// Copyright 2023 RISC Zero, Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

//! The execution phase is implemented by this module.
//!
//! The result of the execution phase is a [Session]. Each [Session] contains
//! one or more [Segment]s, each of which contains an execution trace of the
//! specified program.

#![allow(missing_docs)]
mod env;
pub(crate) mod io;
// mod monitor;
mod ecall;
mod memory;
use std::collections::BTreeSet;
#[cfg(feature = "profiler")]
pub(crate) mod profiler;
mod rv32im;
#[cfg(test)]
mod tests;

use std::{cell::RefCell, fmt::Debug, io::Write, mem::take, rc::Rc};

use anyhow::{bail, Context, Result};
use ecall::{exec_ecall, ECallRecord};
use memory::{image_to_ram, ram_to_image, Dir, PageTable, CYCLES_PER_FULL_PAGE};
use risc0_zkp::ZK_CYCLES;
use risc0_zkvm_platform::{
    fileno,
    memory::{MEM_SIZE, SYSTEM},
    PAGE_SIZE, WORD_SIZE,
};
use rv32im::{exec_rv32im, InstRecord, MachineState};
use serde::{Deserialize, Serialize};

pub use self::env::{ExecutorEnv, ExecutorEnvBuilder};
use crate::{
    exec::io::SyscallContext, receipt::ExitCode, session::PageFaults, Loader, MemoryImage, Program,
    Segment, SegmentRef, Session, SimpleSegmentRef,
};

#[derive(Debug)]
enum OpRecord {
    InstRecord(InstRecord),
    ECallRecord(ECallRecord),
}

/// The number of cycles required to compress a SHA-256 block.
const SHA_CYCLES: usize = 72;

/// The Executor provides an implementation for the execution phase.
///
/// The proving phase uses an execution trace generated by the Executor.
pub struct Executor<'a> {
    pre_image: MemoryImage,
    image: MemoryImage,
    env: ExecutorEnv<'a>,

    // Number of cycles available before we have to split.
    cycles_remaining: usize,

    // Total number of cycles in this segment
    segment_limit: usize,

    // Cycles in various parts of this segment
    init_cycles: usize,
    body_cycles: usize,
    fini_cycles: usize,

    // Cycles used in previous segments.
    prev_segment_cycles: usize,

    // Current program counter and registers
    pc: u32,
    regs: [u32; 32],
    ram: Vec<u8>,
    page_table: PageTable,
    // Operation that's been executed but not applied to the current state.
    pending_op: Option<OpRecord>,

    // Record of all ECall::Software system calls eecuted
    syscalls: Vec<SyscallRecord>,

    segments: Vec<Box<dyn SegmentRef>>,

    insn_counter: Option<usize>,
    split_insn: Option<u32>,
}

#[derive(Clone, Serialize, Deserialize, Debug)]
pub struct SyscallRecord {
    pub to_guest: Vec<u32>,
    pub regs: (u32, u32),
}

// Capture the journal output in a buffer that we can access afterwards.
#[derive(Clone, Default)]
struct Journal {
    buf: Rc<RefCell<Vec<u8>>>,
}

impl Write for Journal {
    fn write(&mut self, bytes: &[u8]) -> std::io::Result<usize> {
        self.buf.borrow_mut().write(bytes)
    }

    fn flush(&mut self) -> std::io::Result<()> {
        self.buf.borrow_mut().flush()
    }
}

impl<'a> MachineState for Executor<'a> {
    fn load_ram(&self, addr: u32) -> u32 {
        u32::from_le_bytes(
            self.ram[addr as usize..addr as usize + WORD_SIZE]
                .try_into()
                .unwrap(),
        )
    }
    fn load_reg(&self, reg_idx: usize) -> u32 {
        self.regs[reg_idx]
    }
}

impl<'a> SyscallContext for Executor<'a> {
    fn get_cycle(&self) -> usize {
        self.prev_segment_cycles + self.init_cycles + (self.body_cycles - self.cycles_remaining)
    }

    fn load_register(&self, reg: usize) -> u32 {
        self.regs[reg]
    }

    fn load_u32(&self, addr: u32) -> u32 {
        u32::from_le_bytes(
            self.ram[addr as usize..addr as usize + WORD_SIZE]
                .try_into()
                .unwrap(),
        )
    }

    fn load_u8(&self, addr: u32) -> u8 {
        self.ram[addr as usize]
    }
}

impl<'a> Executor<'a> {
    /// Construct a new [Executor] from a [MemoryImage] and entry point.
    ///
    /// Before a guest program is proven, the [Executor] is responsible for
    /// deciding where a zkVM program should be split into [Segment]s and what
    /// work will be done in each segment. This is the execution phase:
    /// the guest program is executed to determine how its proof should be
    /// divided into subparts.
    pub fn new(env: ExecutorEnv<'a>, image: MemoryImage, pc: u32) -> Self {
        let loader = Loader::new();
        let init_cycles = loader.init_cycles();
        let fini_cycles = loader.fini_cycles()
            + SHA_CYCLES        // Final journal digest.
            + ZK_CYCLES; // Cycles reserved for ZK elements
        let segment_limit = env.get_segment_limit();
        let body_cycles = segment_limit - init_cycles - fini_cycles;
        let pre_image = image.clone();
        let page_table = PageTable::new(image.info.clone(), MEM_SIZE);
        let mut exec = Self {
            env,
            image,
            pc,
            init_cycles,
            fini_cycles,
            segment_limit,
            ram: vec![0u8; MEM_SIZE],
            page_table,
            body_cycles,
            cycles_remaining: 0,
            insn_counter: None,
            pending_op: None,
            pre_image,
            regs: Default::default(),
            prev_segment_cycles: 0,
            segments: Vec::new(),
            split_insn: None,
            syscalls: Vec::new(),
        };

        image_to_ram(&exec.image, &mut exec.ram);
        exec.image.load_region_in_page(
            SYSTEM.start() as u32,
            bytemuck::cast_slice_mut(&mut exec.regs),
        );
        exec.start_segment();
        exec
    }

    fn start_segment(&mut self) {
        self.pre_image = self.image.clone();
        self.insn_counter = None;
        self.cycles_remaining = self.segment_limit - self.init_cycles - self.fini_cycles;
        self.cycles_remaining -= self.page_table.mark_root();
    }

    fn segment_cycle(&self) -> usize {
        self.segment_limit - self.cycles_remaining
    }

    fn finish_segment(&mut self) -> PageFaults {
        self.prev_segment_cycles += self.segment_cycle();

        let faults = self.page_table.calc_page_faults();
        self.page_table.clear();

        ram_to_image(&mut self.image, &self.ram, faults.writes.iter().cloned());
        self.image
            .store_region_in_page(SYSTEM.start() as u32, bytemuck::cast_slice(&self.regs));

        log::debug!("Faults: {faults:?}");

        faults
    }

    /// Construct a new [Executor] from the ELF binary of the guest program you
    /// want to run and an [ExecutorEnv] containing relevant environmental
    /// configuration details.
    /// # Example
    /// ```
    /// use risc0_zkvm::{serde::to_vec, Executor, ExecutorEnv, Session};
    /// use risc0_zkvm_methods::{BENCH_ELF, bench::{BenchmarkSpec, SpecWithIters}};
    ///
    /// let spec = SpecWithIters(BenchmarkSpec::SimpleLoop, 1);
    /// let env = ExecutorEnv::builder()
    ///     .add_input(&to_vec(&spec).unwrap())
    ///     .build();
    /// let mut exec = Executor::from_elf(env, BENCH_ELF).unwrap();
    /// ```
    pub fn from_elf(env: ExecutorEnv<'a>, elf: &[u8]) -> Result<Self> {
        let program = Program::load_elf(&elf, MEM_SIZE as u32)?;
        let image = MemoryImage::new(&program, PAGE_SIZE as u32)?;
        Ok(Self::new(env, image, program.entry))
    }

    /// Run the executor until [ExitCode::Paused] or [ExitCode::Halted] is
    /// reached, producing a [Session] as a result.
    /// # Example
    /// ```
    /// use risc0_zkvm::{serde::to_vec, Executor, ExecutorEnv, Session};
    /// use risc0_zkvm_methods::{BENCH_ELF, bench::{BenchmarkSpec, SpecWithIters}};
    ///
    /// let spec = SpecWithIters(BenchmarkSpec::SimpleLoop, 1);
    /// let env = ExecutorEnv::builder()
    ///    .add_input(&to_vec(&spec).unwrap())
    ///    .build();
    /// let mut exec = Executor::from_elf(env, BENCH_ELF).unwrap();
    /// let session = exec.run().unwrap();
    /// ```
    pub fn run(&mut self) -> Result<Session> {
        self.run_with_callback(|segment| Ok(Box::new(SimpleSegmentRef::new(segment))))
    }

    /// Run the executor until [ExitCode::Paused] or [ExitCode::Halted] is
    /// reached, producing a [Session] as a result.
    pub fn run_with_callback<F>(&mut self, mut callback: F) -> Result<Session>
    where
        F: FnMut(Segment) -> Result<Box<dyn SegmentRef>>,
    {
        let journal = Journal::default();
        self.env
            .io
            .borrow_mut()
            .with_write_fd(fileno::JOURNAL, journal.clone());

        let mut run_loop = || -> Result<ExitCode> {
            loop {
                if let Some(exit_code) = self.step()? {
                    let pre_image = self.pre_image.clone();
                    self.image.hash_pages();
                    let post_image_id = self.image.compute_id();
                    let syscalls = take(&mut self.syscalls);
                    let segment_cycle = self.segment_limit - self.cycles_remaining;
                    let faults = self.finish_segment();
                    let segment = Segment::new(
                        pre_image,
                        post_image_id,
                        faults,
                        syscalls,
                        exit_code,
                        self.split_insn,
                        self.env.segment_limit_po2,
                        self.segments
                            .len()
                            .try_into()
                            .context("Too many segments to fit in u32")?,
                        segment_cycle,
                    );
                    let segment_ref = callback(segment)?;
                    self.segments.push(segment_ref);
                    match exit_code {
                        ExitCode::SystemSplit => {
                            self.start_segment();
                        }
                        ExitCode::SessionLimit => bail!("Session limit exceeded"),
                        ExitCode::Paused(inner) => {
                            log::debug!("Paused({inner}): {}", self.segment_cycle());
                            self.start_segment();
                            return Ok(exit_code);
                        }
                        ExitCode::Halted(inner) => {
                            log::debug!("Halted({inner}): {}", self.segment_cycle());
                            return Ok(exit_code);
                        }
                    }
                }
            }
        };
        let exit_code = run_loop()?;
        Ok(Session::new(
            take(&mut self.segments),
            journal.buf.take(),
            exit_code,
        ))
    }

    pub fn step(&mut self) -> Result<Option<ExitCode>> {
        log::trace!(
            "Step at pc={:#08x}, pending_op = {:?}",
            self.pc,
            &self.pending_op
        );
        match self.pending_op.take() {
            Some(op) => self.apply(op),
            None => {
                let op = OpRecord::InstRecord(exec_rv32im(self.pc, self)?);
                self.apply(op)
            }
        }
    }

    fn calc_ecall_pages(&self, ecall: &ECallRecord) -> (BTreeSet<u32>, BTreeSet<u32>) {
        match ecall {
            ECallRecord {
                ram_writes,
                page_loads,
                ..
            } => {
                let mut page_loads = page_loads.clone();
                let page_stores: BTreeSet<u32> = ram_writes
                    .iter()
                    .map(|(addr, _val)| addr / PAGE_SIZE as u32)
                    .collect();
                page_loads.extend(page_stores.iter());

                let page_loads_needed: BTreeSet<u32> = page_loads
                    .iter()
                    .flat_map(|page_idx| self.page_table.pages_needed(*page_idx, Dir::Load))
                    .collect();
                let page_stores_needed: BTreeSet<u32> = page_stores
                    .iter()
                    .flat_map(|page_idx| self.page_table.pages_needed(*page_idx, Dir::Store))
                    .collect();

                (page_loads_needed, page_stores_needed)
            }
        }
    }

    fn apply(&mut self, op: OpRecord) -> Result<Option<ExitCode>> {
        assert!(
            self.pending_op.is_none(),
            "Apply needs to be able to reschedule a pending op"
        );
        let mut cycles_needed = match &op {
            OpRecord::InstRecord(InstRecord::ECall) => {
                // Execute the ecall, and try to apply it next loop.
                let ecall = exec_ecall(self, &self.env)?;
                self.pending_op = Some(OpRecord::ECallRecord(ecall));
                return Ok(None);
            }
            OpRecord::InstRecord(InstRecord::MemoryLoad { addr, .. }) => {
                self.page_table
                    .cycles_needed(addr / PAGE_SIZE as u32, Dir::Load)
                    + 1
            }
            OpRecord::InstRecord(InstRecord::MemoryStore { addr, .. }) => {
                self.page_table
                    .cycles_needed(addr / PAGE_SIZE as u32, Dir::Load)
                    + self
                        .page_table
                        .cycles_needed(addr / PAGE_SIZE as u32, Dir::Store)
                    + 1
            }
            OpRecord::InstRecord(InstRecord::RegisterStore { cycles, .. }) => *cycles,
            OpRecord::ECallRecord(ecall @ ECallRecord { cycles, .. }) => {
                let (page_loads, page_stores) = self.calc_ecall_pages(ecall);
                (page_loads.len() + page_stores.len()) * CYCLES_PER_FULL_PAGE + cycles
            }
        };

        cycles_needed += self
            .page_table
            .cycles_needed(self.pc / PAGE_SIZE as u32, Dir::Load);

        if cycles_needed >= self.cycles_remaining {
            return Ok(Some(ExitCode::SystemSplit));
        }

        self.cycles_remaining -= self.page_table.mark_addr(self.pc, Dir::Load);

        match op {
            OpRecord::InstRecord(InstRecord::ECall) => {
                panic!("Encountered un-executed ECall OpRecord")
            }
            OpRecord::InstRecord(InstRecord::MemoryLoad { addr, val, reg }) => {
                self.cycles_remaining -= 1;
                self.cycles_remaining -= self.page_table.mark_addr(addr, Dir::Load);
                self.regs[reg] = val;
                self.pc += WORD_SIZE as u32;
                Ok(None)
            }
            OpRecord::InstRecord(InstRecord::MemoryStore { addr, val }) => {
                let write_cycles = self.page_table.mark_addr(addr, Dir::Store);
                if write_cycles > 0 {
                    self.cycles_remaining -= write_cycles;
                    self.cycles_remaining -= self.page_table.mark_addr(addr, Dir::Load);
                }
                self.cycles_remaining -= 1;
                self.ram[addr as usize..addr as usize + WORD_SIZE]
                    .clone_from_slice(&val.to_le_bytes());
                self.pc += WORD_SIZE as u32;
                Ok(None)
            }
            OpRecord::InstRecord(InstRecord::RegisterStore {
                reg,
                val,
                new_pc,
                cycles,
            }) => {
                self.cycles_remaining -= cycles;
                if reg != 0 {
                    self.regs[reg] = val;
                }
                self.pc = new_pc;
                Ok(None)
            }
            OpRecord::ECallRecord(ecall) => {
                let (page_loads, page_stores) = self.calc_ecall_pages(&ecall);

                let ECallRecord {
                    ram_writes,
                    reg_writes,
                    syscall,
                    exit_code,
                    cycles,
                    ..
                } = ecall;

                self.cycles_remaining -= cycles;
                for page_idx in page_loads {
                    self.cycles_remaining -= self.page_table.mark_page(page_idx, Dir::Load);
                }
                for page_idx in page_stores {
                    self.cycles_remaining -= self.page_table.mark_page(page_idx, Dir::Store);
                }

                for (reg, val) in reg_writes.iter() {
                    self.regs[*reg] = *val;
                }
                for (addr, val) in ram_writes.iter() {
                    self.ram[*addr as usize..*addr as usize + WORD_SIZE]
                        .clone_from_slice(&val.to_le_bytes());
                }
                if let Some(syscall) = syscall {
                    self.syscalls.push(syscall);
                }
                self.pc += WORD_SIZE as u32;
                Ok(exit_code)
            }
        }
    }
}

/// An event traced from the running VM.
#[derive(Clone, Eq, Ord, PartialEq, PartialOrd)]
pub enum TraceEvent {
    /// An instruction has started at the given program counter
    InstructionStart {
        /// Cycle number since startup
        cycle: u32,
        /// Program counter of the instruction being executed
        pc: u32,
    },

    /// A register has been set
    RegisterSet {
        /// Register ID (0-16)
        reg: usize,
        /// New value in the register
        value: u32,
    },

    /// A memory location has been written
    MemorySet {
        /// Address of word that's been written
        addr: u32,
        /// Value of word that's been written
        value: u32,
    },
}

impl Debug for TraceEvent {
    fn fmt(&self, f: &mut core::fmt::Formatter<'_>) -> core::fmt::Result {
        match self {
            Self::InstructionStart { cycle, pc } => {
                write!(f, "InstructionStart({cycle}, 0x{pc:08X})")
            }
            Self::RegisterSet { reg, value } => write!(f, "RegisterSet({reg}, 0x{value:08X})"),
            Self::MemorySet { addr, value } => write!(f, "MemorySet(0x{addr:08X}, 0x{value:08X})"),
        }
    }
}
